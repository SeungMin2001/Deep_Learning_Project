from dotenv import load_dotenv
import os
import re
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from tabulate import tabulate  # pip install tabulate
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

class Step5:
    def last(self,x):
        import os  # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ import
        import glob  # íŒŒì¼ ê²€ìƒ‰ì„ ìœ„í•œ import
        
        # ë³´ê³ ì„œ í´ë” ì¡´ì¬ í™•ì¸ ë° ìŠ¤í‚µ ë¡œì§
        docx_folder = "reports_docx.v8"
        md_folder = "generated_reports"
        
        # DOCX í´ë” í™•ì¸
        docx_files_exist = False
        if os.path.exists(docx_folder):
            docx_files = glob.glob(os.path.join(docx_folder, "*.docx"))
            if docx_files:
                docx_files_exist = True
                print(f"âœ… {docx_folder} í´ë”ì— {len(docx_files)}ê°œì˜ DOCX ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                for file in docx_files[:3]:  # ìµœëŒ€ 3ê°œ íŒŒì¼ëª…ë§Œ í‘œì‹œ
                    print(f"   - {os.path.basename(file)}")
                if len(docx_files) > 3:
                    print(f"   ... ë° {len(docx_files) - 3}ê°œ ë”")
        
        # MD í´ë” í™•ì¸  
        md_files_exist = False
        if os.path.exists(md_folder):
            md_files = glob.glob(os.path.join(md_folder, "*.md"))
            if md_files:
                md_files_exist = True
                print(f"âœ… {md_folder} í´ë”ì— {len(md_files)}ê°œì˜ MD ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                for file in md_files[:3]:  # ìµœëŒ€ 3ê°œ íŒŒì¼ëª…ë§Œ í‘œì‹œ
                    print(f"   - {os.path.basename(file)}")
                if len(md_files) > 3:
                    print(f"   ... ë° {len(md_files) - 3}ê°œ ë”")
        
        # ë‘˜ ë‹¤ ì¡´ì¬í•˜ë©´ ë³´ê³ ì„œ ìƒì„± ê³¼ì •ì„ ê±´ë„ˆë›°ê¸°
        if docx_files_exist and md_files_exist:
            print("ğŸš€ ê¸°ì¡´ ë³´ê³ ì„œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë³´ê³ ì„œ ìƒì„± ê³¼ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        print("ğŸ“ ë³´ê³ ì„œë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        load_dotenv()
        # ğŸŒ LLM ì„ ì–¸
        llm = ChatOpenAI(model="gpt-4o", temperature=0.5)

        # ğŸ·ï¸ í† í”½ ì œëª© ìƒì„± í”„ë¡¬í”„íŠ¸
        title_prompt_template = ChatPromptTemplate.from_messages([
            ("system",
            "ë„ˆëŠ” ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ê°€ì•¼. ì£¼ì–´ì§„ í‚¤ì›Œë“œë“¤ì„ ë¶„ì„í•´ì„œ í•´ë‹¹ ê¸°ìˆ  ë¶„ì•¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” "
            "ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ ì œëª©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.\n\n"
            "ğŸ“Œ ì œëª© ìƒì„± ê·œì¹™:\n"
            "- í‚¤ì›Œë“œë“¤ ê°„ì˜ ê¸°ìˆ ì  ì—°ê´€ì„±ì„ íŒŒì•…í•´ì„œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±\n"
            "- ë‹¨ìˆœ í‚¤ì›Œë“œ ë‚˜ì—´ì´ ì•„ë‹Œ, ê¸°ìˆ ì˜ ëª©ì ì´ë‚˜ ì‘ìš© ë¶„ì•¼ê°€ ë“œëŸ¬ë‚˜ëŠ” ì œëª©\n"
            "- 10-15ì ë‚´ì™¸ì˜ ê°„ê²°í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í‘œí˜„\n"
            "- 'ì‹œìŠ¤í…œ', 'ê¸°ìˆ ', 'ì†”ë£¨ì…˜' ë“±ì˜ ê¸°ìˆ  ìš©ì–´ í™œìš© ê°€ëŠ¥\n\n"
            "ì˜ˆì‹œ:\n"
            "í‚¤ì›Œë“œ: ì„¼ì„œ, ì „ë ¥, ì˜¨ë„ â†’ ìŠ¤ë§ˆíŠ¸ ì„¼ì„œ ê¸°ë°˜ ì „ë ¥ íš¨ìœ¨ ì œì–´\n"
            "í‚¤ì›Œë“œ: ë¡œë´‡, ì£¼í–‰, ììœ¨ â†’ ììœ¨ì£¼í–‰ ë¡œë´‡ ë„¤ë¹„ê²Œì´ì…˜ ì‹œìŠ¤í…œ\n"
            "í‚¤ì›Œë“œ: ì§€ëŠ¥, ì¸ê³µ, í•™ìŠµ â†’ AI ê¸°ë°˜ ì§€ëŠ¥í˜• í•™ìŠµ í”Œë«í¼"
            ),
            ("human",
            "ë‹¤ìŒ í‚¤ì›Œë“œë“¤ë¡œ ê¸°ìˆ  ì œëª©ì„ ë§Œë“¤ì–´ì¤˜: {keywords}")
        ])

        # ğŸ§¾ ê¸°ìˆ  ë³´ê³ ì„œ ì‘ì„± í”„ë¡¬í”„íŠ¸
        report_prompt_template = ChatPromptTemplate.from_messages([
            ("system",
            "ë„ˆëŠ” ì²¨ë‹¨ ê¸°ìˆ  ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì´ì ê¸°ìˆ  ì „ëµ ì»¨ì„¤í„´íŠ¸ì•¼. "
            "ë‹¤ìŒ ì£¼ì œ ì œëª©ê³¼ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì—…ì´ ì‹¤ì œë¡œ ì‚¬ì—…í™” ì „ëµì„ ì„¸ìš¸ ìˆ˜ ìˆë„ë¡ ê¸°ìˆ  ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. "
            "ë³´ê³ ì„œ ë‚´ìš©ì— ë‹¤ì‹œ ì£¼ì œ ì œëª©ì„ ëª…ì‹œí•  í•„ìš”ëŠ” ì—†ì–´.\n\n"

            "**ê° í•­ëª©ì€ ë°˜ë“œì‹œ 'í•­ëª©ëª…:' í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´.**\n"
            "ì˜ˆ: 'ê°œìš”: ...'\n\n"

            "ğŸ“Œ ì‘ì„± ê·œì¹™:\n"
            "- ê° í•­ëª©ì€ ë‹¨ìˆœ ì„¤ëª…ì´ ì•„ë‹ˆë¼ ê¸°ì—…ì´ ì‹¤ì§ˆì ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•œ ì „ëµì„ í¬í•¨í•´ì•¼ í•´.\n"
            "- 'ê¸°ìˆ  êµ¬ì„±', 'ì ìš© ë¶„ì•¼', 'ê°œë°œ ë‹¨ê³„ë³„ ëª©í‘œ', 'ê´€ë ¨ ê¸°ìˆ  ë³´ìœ  ê¸°ì—… ë° ì œì¡°ì‚¬ í˜„í™©' í•­ëª©ì—ì„œëŠ” **ê° ì„¸ë¶€ ê¸°ìˆ  ë˜ëŠ” ì‚¬ë¡€ë§ˆë‹¤ ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ ë²ˆí˜¸ì—†ì´ ê´„í˜¸ë¡œ ì œì‹œí•œ í›„ ì„¤ëª…í•˜ëŠ” ë°©ì‹**ìœ¼ë¡œ ì‘ì„±í•´ì¤˜.\n"
            "  ì˜ˆ: (ì£¼í–‰ ê¸°ìˆ ) ì‹¤ë‚´ í™˜ê²½ ë§µí•‘ê³¼ ììœ¨ ê²½ë¡œ ì„¤ì • ê¸°ìˆ ì„ í†µí•´...\n"
            "- ê¸°ìˆ  êµ¬ì„± í•­ëª©ì—ì„œëŠ” í•µì‹¬ ê¸°ìˆ ë³„ ì°¨ë³„í™” í¬ì¸íŠ¸ ë° êµ¬í˜„ ë°©ì•ˆì„ ì œì‹œí•´.\n"
            "- ì ìš© ë¶„ì•¼ì—ì„œëŠ” ìˆ˜ìš”ê°€ ìˆëŠ” ì‚°ì—… ë° ì‹œì¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ê³ , ì‹œì¥ ê·œëª¨ë‚˜ ì„±ì¥ ê°€ëŠ¥ì„±ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•´.\n"
            "- ê°œë°œ ë‹¨ê³„ë³„ ëª©í‘œëŠ” (1ì°¨ë…„ë„), (2ì°¨ë…„ë„), (3ì°¨ë…„ë„) ê¹Œì§€ë§Œ ì œì‹œí•˜ê³ , ì—°ì°¨ë³„ R&D ì „ëµê³¼ ì‹¤ì¦ ë˜ëŠ” ì œí’ˆí™” ìˆ˜ì¤€ì„ ê³ ë ¤í•´ì„œ ì‘ì„±í•´.\n"
            "- í™œìš© ê°€ëŠ¥ì„±ì€ ê¸°ìˆ ì˜ íŒŒê¸‰ë ¥, í™•ì¥ ê°€ëŠ¥ì„±, íƒ€ ê¸°ìˆ ê³¼ì˜ ìœµí•© ê°€ëŠ¥ì„±ì„ ì œì•ˆ í˜•íƒœë¡œ ì„œìˆ í•´.\n"
            "- ê´€ë ¨ ê¸°ìˆ  ë³´ìœ  ê¸°ì—… ë° ì œì¡°ì‚¬ í˜„í™©ì€ ì£¼ìš” ê¸°ì—…ë³„ ê¸°ìˆ  íŠ¹ì§•, ì°¨ë³„í™” í¬ì¸íŠ¸, ë²¤ì¹˜ë§ˆí‚¹ ìš”ì†Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´.\n\n"

            "ğŸ“„ í•„ìˆ˜ í•­ëª©:\n"
            "- ê°œìš”\n"
            "- ê¸°ìˆ  êµ¬ì„±\n"
            "- ì ìš© ë¶„ì•¼\n"
            "- ê°œë°œ ë‹¨ê³„ë³„ ëª©í‘œ\n"
            "- ìµœì¢… ëª©í‘œ\n"
            "- í™œìš© ê°€ëŠ¥ì„±\n"
            "- ê´€ë ¨ ê¸°ìˆ  ë³´ìœ  ê¸°ì—… ë° ì œì¡°ì‚¬ í˜„í™©\n\n"

            "ë³´ê³ ì„œëŠ” ê¸°ì—… ì‹¤ë¬´ì, íˆ¬ìì ë˜ëŠ” ê¸°ìˆ  ê¸°íšìê°€ ë°”ë¡œ ì°¸ê³ í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ "
            "**ëª…í™•í•˜ê³  ì „ëµì ì´ë©°, ì „ë¬¸ì ì¸ ë¬¸ì¥**ìœ¼ë¡œ êµ¬ì„±í•´ì¤˜. "
            "ê¸°ìˆ  ì†Œê°œê°€ ì•„ë‹ˆë¼, ê¸°ìˆ  ê¸°ë°˜ ì‚¬ì—… ì „ëµ ë³´ê³ ì„œë¼ëŠ” ì ì„ ê¼­ ê¸°ì–µí•´ì¤˜."
            ),

            ("human",
            "ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.\n\n"
            "ì œëª©: {title}\n"
            "í•µì‹¬ í‚¤ì›Œë“œ: {keywords}")
        ])

        # ğŸ“š ì„¹ì…˜ ì œëª© í›„ë³´ ë¦¬ìŠ¤íŠ¸
        SECTION_TITLES = [
            "ê°œìš”", "ê¸°ìˆ  êµ¬ì„±", "ì ìš© ë¶„ì•¼",
            "ê°œë°œ ë‹¨ê³„ë³„ ëª©í‘œ", "ìµœì¢… ëª©í‘œ",
            "í™œìš© ê°€ëŠ¥ì„±", "ê´€ë ¨ ê¸°ìˆ  ë³´ìœ  ê¸°ì—… ë° ì œì¡°ì‚¬ í˜„í™©"
        ]

        # ğŸ§¹ ì‘ë‹µ ì •ë¦¬ ë° ë§ˆí¬ë‹¤ìš´ Bold ì²˜ë¦¬
        def clean_and_format_report(report_text):
            paragraphs = []
            current_section = None
            content_accumulator = []

            lines = report_text.strip().split("\n")
            for line in lines:
                line = line.strip()
                if not line:
                    continue

                is_section = False
                for title in SECTION_TITLES:
                    if re.match(fr"^(#+\s*)?\d*[\.\)]?\s*{title}[:ï¼š]?$", line, re.IGNORECASE):
                        if current_section:
                            paragraphs.append((current_section, "\n".join(content_accumulator).strip()))
                            content_accumulator = []
                        current_section = title
                        is_section = True
                        break

                if not is_section:
                    content_accumulator.append(line)

            if current_section:
                paragraphs.append((current_section, "\n".join(content_accumulator).strip()))

            return paragraphs

        # ğŸ§¾ ë§ˆí¬ë‹¤ìš´ Bold ì²˜ë¦¬ í•¨ìˆ˜ (í…ìŠ¤íŠ¸ ë‚´ **ë¶€ë¶„ Bold ì²˜ë¦¬)
        def add_markdown_paragraph(doc, text):
            p = doc.add_paragraph()

            # 1ï¸âƒ£ "- í‚¤ì›Œë“œ:" í˜•íƒœë¥¼ ëª¨ë‘ "(**í‚¤ì›Œë“œ**)" ë¡œ ë³€ê²½
            text = re.sub(r"^- ([^:]+?)\s*:\s*", r"(\1) ", text)

            # 2ï¸âƒ£ ë§ˆí¬ë‹¤ìš´ êµµì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (**í…ìŠ¤íŠ¸**)
            pattern = r"(\(\*\*.+?\*\*\))"
            pos = 0
            for match in re.finditer(pattern, text):
                if match.start() > pos:
                    p.add_run(text[pos:match.start()]).font.size = Pt(11)

                bold_text = match.group(2)
                run = p.add_run(bold_text)
                run.bold = True
                run.font.size = Pt(11)
                pos = match.end()

            if pos < len(text):
                p.add_run(text[pos:]).font.size = Pt(11)

            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY


        # ğŸ“¤ Word ì €ì¥ í•¨ìˆ˜
        def save_report_as_docx(title, keywords, report_text, filename):
            doc = Document()

            # ì œëª©
            doc.add_heading(title, level=1)

            # í‚¤ì›Œë“œ
            p_kw = doc.add_paragraph()
            run_kw = p_kw.add_run(f"í•µì‹¬ í‚¤ì›Œë“œ: {keywords}")
            run_kw.bold = True
            run_kw.font.size = Pt(11)

            # ë³¸ë¬¸ êµ¬ì„±
            cleaned_sections = clean_and_format_report(report_text)
            for section_title, content in cleaned_sections:
                # ì„¹ì…˜ ì œëª©
                p_title = doc.add_paragraph()
                run_title = p_title.add_run(section_title)
                run_title.bold = True
                run_title.font.size = Pt(13)

                # ì„¹ì…˜ ë‚´ìš©
                for paragraph in content.split('\n'):
                    paragraph = paragraph.strip()
                    if paragraph:
                        add_markdown_paragraph(doc, paragraph)

            os.makedirs("reports_docx.v8", exist_ok=True)
            filepath = os.path.join("reports_docx.v8", filename)
            doc.save(filepath)
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {filepath}")

        # ğŸ” ì‹¤í–‰ í•¨ìˆ˜ (step4ì—ì„œ ë°˜í™˜ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬)
        def generate_reports_from_results(topics_dict):
            if not isinstance(topics_dict, dict):
                print("âŒ í† í”½ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤.")
                return
                
            for topic_num, keywords in topics_dict.items():
                # í† í”½ ì œëª© ìƒì„± (LLMì´ í‚¤ì›Œë“œë¡œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ìƒì„±)
                keywords_for_title = ', '.join(keywords[:5])  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë¡œ ì œëª© ìƒì„±
                title_chain = title_prompt_template | llm
                title_response = title_chain.invoke({"keywords": keywords_for_title})
                generated_title = title_response.content.strip() if hasattr(title_response, 'content') else str(title_response).strip()
                
                title = f"Topic {topic_num}: {generated_title}"
                keywords_str = ', '.join(keywords[:10])  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ
                
                print(f"\nğŸš€ ìƒì„± ì¤‘: {title}")
                report_chain = report_prompt_template | llm
                response = report_chain.invoke({"title": title, "keywords": keywords_str})

                report_text = (
                    response.strip()
                    if isinstance(response, str)
                    else response.content.strip()
                )

                filename = f"{topic_num}_{title[:30].replace(' ', '_').replace(':', '')}.docx"
                save_report_as_docx(title, keywords_str, report_text, filename)

        # âœ… DOCX ë³´ê³ ì„œ ìƒì„± (ì¡°ê±´ë¶€)
        if not docx_files_exist:
            print("ğŸ“„ DOCX ë³´ê³ ì„œë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
            generate_reports_from_results(x)
        else:
            print("ğŸ“„ DOCX ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # í‘œ í˜•íƒœ ì¶œë ¥ (ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜)
        table_data = []
        for topic_num, keywords in x.items():
            table_data.append([f"Topic {topic_num}", f"Topic {topic_num}", ', '.join(keywords[:5])])
        
        headers = ["í† í”½ ë²ˆí˜¸", "í† í”½", "ì£¼ìš” í‚¤ì›Œë“œ"]
        print(tabulate(table_data, headers=headers, tablefmt="github"))


        # ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
        os.makedirs("generated_reports", exist_ok=True)
        
        # MD ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if md_files_exist:
            print("ğŸ“ MD ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ MD ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            print("ğŸ“ MD ë³´ê³ ì„œë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
            
            # step4ì—ì„œ ë°˜í™˜ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ë°ì´í„° ì²˜ë¦¬
            for topic_id, keywords_list in x.items():
                # í† í”½ ì œëª© ìƒì„± (LLMì´ í‚¤ì›Œë“œë¡œ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ìƒì„±)
                keywords_for_title = ', '.join(keywords_list[:5])  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë¡œ ì œëª© ìƒì„±
                title_chain = title_prompt_template | llm
                title_response = title_chain.invoke({"keywords": keywords_for_title})
                generated_title = title_response.content.strip() if hasattr(title_response, 'content') else str(title_response).strip()
                
                topic_name = f"Topic {topic_id}: {generated_title}"
                keywords_str = ', '.join(keywords_list[:10])  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                
                # 1. ë³´ê³ ì„œ ìƒì„±
                chain = report_prompt_template | llm
                response = chain.invoke({"title": topic_name, "keywords": keywords_str})
                report_text = response.content.strip()

                # 2. Markdown íŒŒì¼ë¡œ ì €ì¥
                filename = f"Topic_{topic_id}_{keywords_list[0] if keywords_list else 'empty'}_{keywords_list[1] if len(keywords_list) > 1 else ''}.md"
                filename = filename.replace(' ', '_').replace('/', '_').replace('\\', '_')[:50] + '.md'  # íŒŒì¼ëª… ì •ë¦¬
                filepath = os.path.join("./generated_reports", filename)

                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(f"# {topic_name}\n")
                    f.write(f"**í•µì‹¬ í‚¤ì›Œë“œ:** {keywords_str}\n\n")
                    f.write(report_text)

                print(f"âœ… ì €ì¥ ì™„ë£Œ: {filepath}")
